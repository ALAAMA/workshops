#    -*- mode: org -*-


Archived entries from file /Users/astorer/Work/presentations/Python-June2013/workshop.org


* Web scraping: selenium
  :PROPERTIES:
  :ARCHIVE_TIME: 2013-06-05 Wed 10:51
  :ARCHIVE_FILE: ~/Work/presentations/Python-June2013/workshop.org
  :ARCHIVE_OLPATH: Web scraping technology
  :ARCHIVE_CATEGORY: workshop
  :END:

#+begin_src python :eval no
from selenium import webdriver  
import time

browser = webdriver.Firefox()
thisurl = 'http://www.egyptindependent.com/subchannel/News%20features'
browser.get(thisurl)

time.sleep(10)
nextpage = [False]
all_links = []

while len(nextpage)>0:
    if nextpage[0]:
        nextpage[0].click()
        time.sleep(10)
    elems = browser.find_elements_by_xpath("//div[@class='view-content']/h3/a")
    for e in elems:
        all_links.append(e.get_attribute('href'))
    nextpage = browser.find_elements_by_xpath("//li[@class='pager-next last']/a")
#+end_src

Let's go through this code in some more detail:

We begin by importing the necessary libraries, and then starting a
new Firefox browser.  The =browser.get()= command navigates this
browser to a given URL.

#+begin_src python :eval no
from selenium import webdriver  
import time

browser = webdriver.Firefox()
thisurl = 'http://www.egyptindependent.com/subchannel/News%20features'
browser.get(thisurl)
#+end_src

Unfortunately, there is no clear way to tell if the page is done
loading.  The easiest strategy is to just wait a long-ish amount of
time (I choose 10 seconds).  We will use a list to hold the URLs of
the pages we want to download, focusing now on just building that
list.

We also want to know if we need to click on the next page.

#+begin_src python :eval no
time.sleep(10)
nextpage = [False]
all_links = []
#+end_src

#+begin_src python :eval no
while len(nextpage)>0:
    if nextpage[0]:
        nextpage[0].click()
        time.sleep(10)
    elems = browser.find_elements_by_xpath("//div[@class='view-content']/h3/a")
    for e in elems:
        all_links.append(e.get_attribute('href'))
    nextpage = browser.find_elements_by_xpath("//li[@class='pager-next last']/a")
#+end_src



